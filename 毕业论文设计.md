# 毕业论文设计



## 一.背景

法律文书中，通过证据表达来得到最事件整体脉络的理解的过程是法官常常需要面对的问题，面对大量的多种类型证据，梳理起来具有一定的难度和复杂性，本实验的目的是为了使用自然语言处理的方法，来减少法官在整理证据的过程中的工作量。具体子任务如下：

- 建立文书的数据集，目标文书的类型是刑事案件的文书，文书中的证据类型可以分为证人的证言证词，当事人的陈述，物证描述等，在这个问题中只涉及当事人陈述和证言证词，并且需要根据文本格式进行细分。
- 分别研究文书的生成质量模块和文书的特征抽取模块，这两个部分可以进行独立的实验，并且可以分别评价
- 对于文书的特征抽取模块，从特征的组织形式，特征的提取方式，数据集的选择，特征的种类和维度四个角度进行实验，找到较为合适的解决方案。
- 文本的生成模块的功能是提高生成文本的阅读效果，同时结合文本本身的信息。包含模型的设计，模型的优化两个问题。
- 在上述的问题基础上进行扩展，文本生成的应用比较广，在评论文本的数据集上应用相同的模型，效果的对比以及模型迁移性的研究。

## 二.相关工作



#### 1.特征处理

对于文书的特征处理模块，特征的组织形式，特征的提取方式，数据集的选择，特征的种类和维度都是需要考虑的，目前来看，较为流行的特征提取方式有

- 使用bert和transformer的预训练加fine tuning模型。【BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding】

这也是当前NLP各个任务提高产出效果的主流方法，通过这种预训练的方式能够很好的帮助下游任务的完成，结合这种方式来提高文本生成的效果也是目前可以采用的方法之一

- 使用主题特征【A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization】

很多相关的论文都提到了类似的方法，使用LDA的语言模型来给出原文中单词的主题信息，再将主题信息补充到单词的embedding向量中

- 使用一些其他的相关信息。组内其他的同学的增加法条相关信息



#### 2.生成模型

文本的生成模块的功能是提高生成文本的阅读效果，同时结合文本本身的信息。包含模型的设计，优化策略两个问题。

模型选择和优化策略的区别在于，前者表示的是模型在训练以及生成中进行的操作，或者是增加可训练的模块，后者则是模型在生成中采用的一些提升的手段。

**+模型选择**

seq2seq是生成模型的最简单的选择，这个设计本身就会包含很多变体，使用LSTM抑或是GRU，或者是使用CNN作为生产模型，都是可以作为对比模型的

- LSTM【】
- GRU【】
- CNNs2s【A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization】

在上述模型的基础之上添加attention机制是常见的思路。【A Neural Attention Model for Abstractive Sentence Summarization】

**+ 修改损失函数**

- 使用互信息作为损失函数的一部分，同时修改互信息的计算方式，使得互信息【Mutual information and diverse decoding improve neural machine translation】

#### 3.优化策略

目前可以提高文本生成质量的策略有很多，对于评论文本生成质量的提高，有一些前置实验，一般而言生成文本的质量主要面临的问题是文本的重复性和文本的平凡语义的问题，这两种问题出现的主要的原因都是s2s模型在使用大数据集进行训练的时候，数据集中的不均衡性导致的，所以一些主流的方法都是借助减少训练文档中的重复单词，或者是为训练文档中的语料按照文本本身的特异性进行打分，借此重新平衡训练集的权重。

主要的解决方案有以下几种。

- 减少文本重复机制
- BEAMsearch机制（以及其优化策略 【A Simple, Fast Diverse Decoding Algorithm for Neural Generation-2016] 】）
- 训练权重的re-weight机制 【Towards Less Generic Responses in Neural Conversation Models: A Statistical Re-weighting Method】

#### 4.强化学习方法

在很多17-18年的论文中都涉及到了强化学习的方法，强化学习的方式在文本摘要当中会出现，在对话系统中也会出现，一般强化学习的模式为生成式对抗或者基于一些常见指标的强化学习。

- 使用基本的强化学习算法SCST【A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization】
- 使用对抗学习的方法【Adversarial learning for neural dialogue generation】
- 同样是提高生成效果的方法【Deep reinforcement learning for dialogue generation】

#### 5.抽取式摘要方法

很多的论文中出现了抽取式摘要和生成式摘要结合的办法，比如point网络，基于GMM的学习方式等。



#### 6.验证方法

- BLEU：验证机器翻译效果的指标
- ROUGE：验证文本摘要和机器翻译效果的指标
- NoW：单词的数量，可以反映出生成文本中包含词汇量的多少，是一个比较直接的反映出文本质量的指标
- idf-avg：单词的平均idf值。表示的是所有单词idf值的和。可以反映出文章中单词的特殊性
- （其他可以评价文章的指标）



## 三.工作计划

研究法律文本的摘要效果，工作的展开依然是围绕着 特征处理，生成模型和优化策略三个方面展开。具体流程如下

#### 建立实验数据集

在之前的实验数据集的基础上进行修正和补足。在实验中发现的之前的数据集中存在的问题是：

- 数据集质量有限，有的文书的证据很多有的文书的证据很少，而且存在着字段遗失的问题。
- 数据集的专业性和事件的脉络性太强，刑事案件中的各种情况比较复杂，然而数据集的大小有限，训练起来比较难

解决方案：

- 参照之前的数据集的构建方式，在其他案由的数据集上进行构建数据集
- 对证据和事实文本质量进行更严格的把控，去除字段缺失，和严重精简的表述文本

额外补充

1. 统一使用在大数据集下训练的word2vec词向量模型，引用来源【】
2. 使用BERT或者类似的中文预训练模型对句子级别进行编码。
3. 使用LDA训练的主题信息数据



另外，还要针对文本生成的任务选择另外的点评数据集作为对比。为了单独说明文本生成模块的效果和迁移能力。

- 点评数据集以从前的点评数据集为基础。
- 

#### 设计基础模型和增加对照

类似的研究给出了很多解决问题的方向，在之前的实验中也给出了一些解决方案的效果和比对结果，基础模型可以确定为使用attention机制的LSTM s2s模型，在此基础上研究生成效果。对照方案如下

- 增加使用GRU的模型对照

- 使用transformer类的模型对照
- 使用BERT预训练模型对照
- 使用抽取式摘要的对照模型
- 在输入文本向量中添加主题信息

#### 模型调优方向

分析模型中各个部分对于最终效果的影响，或者其本身所提供的作用和价值。

- 使用减少重复的机制来提高文本的生成效果。

减少文本重复性，使用惩罚机制，可以优化的点为：

1. 增加窗口化的惩罚机制和指数下降的惩罚机制

2. 在训练数据中增加权重重新平衡过程

- 增加beam search的方法对比，并优化beam search

1. 

## 四.实验进度

在上述模型中提及的模型的对照试验的基础上，需要进行以下实验工作。

1. 数据集准备
   1. 更换案由，选择具有更多数据，数据量更好的案由数据集，并按照案由划分数据集。
   2. 准备词向量和BERT预训练模型。
   3. 准备点评文本
2. 模型开发
   1. 基于attention和GRU的模型
   2. 基于attention和LSTM的模型
   3. 基于CNNs2s的模型
   4. 在transformer基础上做特征处理的模型
   5. 基于BERT预训练的模型
   6. （指标）各种评价指标一般有可以使用的开源库。自己设置的指标需要独自开发
   7. beam search方式的开发
   8. 重复惩罚机制开发
3. 验证阶段
   1. 比对各项模型在法律数据集上的表现，按照案由分割比较。
   2. 比较各个模型的表现效果。
   3. 比较重复惩罚机制在法律文书生成和评论文本生成两个任务上的效果差别
   4. 在上述各个模型的基础上比较增加beam search以及优化方案的效果
   5. 验证跨数据集情况下模型的迁移能力，（在一个数据集上训练，另一个数据集上验证）。





