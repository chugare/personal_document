# 毕业论文设计



## 一.背景

法律文书中，通过证据表达来得到最事件整体脉络的理解的过程是法官常常需要面对的问题，面对大量的多种类型证据，梳理起来具有一定的难度和复杂性，本实验的目的是为了使用自然语言处理的方法，来减少法官在整理证据的过程中的工作量。具体子任务如下：

- 建立文书的数据集，目标文书的类型是刑事案件的文书，文书中的证据类型可以分为证人的证言证词，当事人的陈述，物证描述等，在这个问题中只涉及当事人陈述和证言证词，并且需要根据文本格式进行细分。
- 分别研究文书的生成质量模块和文书的特征抽取模块，这两个部分可以进行独立的实验，并且可以分别评价
- 对于文书的特征抽取模块，特征的组织形式，特征的提取方式，数据集的选择，特征的种类和维度都是需要考虑的
- 文本的生成模块的功能是提高生成文本的阅读效果，同时结合文本本身的信息。包含模型的设计，模型的优化两个问题。
- 在上述的问题基础上进行扩展，文本生成的应用比较广，在评论文本的数据集上应用相同的模型，效果的对比以及模型迁移性的研究。

## 二.相关工作



#### 1.特征处理

对于文书的特征处理模块，特征的组织形式，特征的提取方式，数据集的选择，特征的种类和维度都是需要考虑的，目前来看，较为流行的特征提取方式有

- 使用bert和transformer的预训练加fine tuning模型。【BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding】

这也是当前NLP各个任务提高产出效果的主流方法，通过这种预训练的方式能够很好的帮助下游任务的完成，结合这种方式来提高文本生成的效果也是目前可以采用的方法之一

- 使用主题特征【A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization】

很多相关的论文都提到了类似的方法，使用LDA的语言模型来给出原文中单词的主题信息，再将主题信息补充到单词的embedding向量中

- 使用一些其他的相关信息。组内其他的同学的增加法条相关信息



#### 2.生成模型



#### 2.文本生成模块

文本的生成模块的功能是提高生成文本的阅读效果，同时结合文本本身的信息。包含模型的设计，优化策略两个问题。

模型选择和优化策略的区别在于，前者表示的是模型在训练以及生成中进行的操作，或者是增加可训练的模块，后者则是模型在生成中采用的一些提升的手段。

**+模型选择**

seq2seq是生成模型的最简单的选择，这个设计本身就会包含很多变体，使用LSTM抑或是GRU，或者是使用CNN作为生产模型，都是可以作为对比模型的

- LSTM【】
- GRU【】
- CNNs2s【A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization】

在上述模型的基础之上添加attention机制是常见的思路。【A Neural Attention Model for Abstractive Sentence Summarization】

**+ 修改损失函数**

- 使用互信息作为损失函数的一部分，同时修改互信息的计算方式，使得互信息【Mutual information and diverse decoding improve neural machine translation】

#### 3.优化策略

目前可以提高文本生成质量的策略有很多，对于评论文本生成质量的提高，有一些前置实验，一般而言生成文本的质量主要面临的问题是文本的重复性和文本的平凡语义的问题，这两种问题出现的主要的原因都是s2s模型在使用大数据集进行训练的时候，数据集中的不均衡性导致的，所以一些主流的方法都是借助减少训练文档中的重复单词，或者是为训练文档中的语料按照文本本身的特异性进行打分，借此重新平衡训练集的权重。

主要的解决方案有以下几种。

- 减少文本重复机制
- BEAMsearch机制（以及其优化策略 【A Simple, Fast Diverse Decoding Algorithm for Neural Generation-2016] 】）
- 训练权重的re-weight机制 【Towards Less Generic Responses in Neural Conversation Models: A Statistical Re-weighting Method】

#### 4.强化学习方法

在很多17-18年的论文中都涉及到了强化学习的方法，强化学习的方式在文本摘要当中会出现，在对话系统中也会出现，一般强化学习的模式为生成式对抗或者基于一些常见指标的强化学习。

- 使用基本的强化学习算法SCST【A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization】
- 使用对抗学习的方法【Adversarial learning for neural dialogue generation】
- 同样是提高生成效果的方法【Deep reinforcement learning for dialogue generation】

## 三.工作计划

研究法律文本的摘要效果，工作的展开依然是围绕着 特征处理，生成模型和优化策略三个方面展开。具体流程如下

#### 建立实验数据集

在之前的实验数据集的基础上进行修正和补足。在实验中发现的之前的数据集中存在的问题是：

- 数据集质量有限，有的文书的证据很多有的文书的证据很少，而且存在着字段遗失的问题。
- 数据集的专业性和事件的脉络性太强，刑事案件中的各种情况比较复杂，然而数据集的大小有限，训练起来比较难

解决方案：

- 参照之前的数据集的构建方式，在其他案由的数据集上进行构建数据集
- 对证据和事实文本质量进行更严格的把控，去除字段缺失，和严重精简的表述文本

#### 设计基础模型和增加对照

类似的研究给出了很多解决问题的方向，在之前的实验中也给出了一些解决方案的效果和比对结果，基础模型可以确定为使用attention机制的LSTM s2s模型，在此基础上研究生成效果。对照方案如下

- 增加使用







## 四.试验进度





