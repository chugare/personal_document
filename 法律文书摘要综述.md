# 法律文书摘要综述

法律文书中，通过证据表达来得到最事件整体脉络的理解的过程是法官常常需要面对的问题，面对大量的多种类型证据，梳理起来具有一定的难度和复杂性，例如在案件XXX中，法官需要对于多个事件的多个事实的细节进行判断，证人的证词之间往往有相互印证的情况，如果有自动化的生成工具能够根据证词，找出证人之间相互印证的点，将有助于法官对于实际情况进行判断，除此之外，法官在撰写法律文书的时候往往会遵照一定的规则和书写规范，在这个过程中如果借助文本自动化的生成工具，也将极大的提高法官的工作效率。

在这个应用背景下，涉及到自然语言处理领域的多个应用方面，分别是事实信息的抽取，文本的自动生成，或者将这个问题看作一个整体，作为一个文本自动摘要的问题进行研究。现如今的nlp领域对于文本的自动生成和文本自动摘要都有很高的兴趣，文本自动摘要的方法也在不断地创新，效果不断的变好，我要研究的内容，重点关注于使用文本自动摘要技术从法律文书的证据信息中生成事实的摘要，并且使用文本生成技术来改善文本自动生成的效果和质量。

## 一.研究背景

文本摘要技术分为抽取式摘要和生成式摘要两种，抽取式摘要侧重于从原文中找出和文本中心相关联的句子或者单词，将其作为文书的摘要选择出来，主要的过程是对句子进行打分或者分类的过程。而生成式摘要的摘要的产生过程则是由一步步的单词生成完成的，最终由模型判定生成结束或者自行截断。

#### 抽取式文本摘要

抽取式的文本摘要具有抽取的文本可读性高，和文章内容关联强的优点，但是抽取式的文本摘要模型在文章中没有明确总结的时候无法对文章内容进行进一步的抽象。抽取式摘要的一般方法分为打分和分类。

- 打分式

打分就是对原文中的段落按照总结的作用进行打分，具有较高总结特性的文本具有更高的的得分。这一类方法往往是基于直接的计算的，例如textRank，lexRank，有些使用了神经网络的模型也会产生一个评分，作为段落是否可以成为摘要的依据。

- 分类式

分类的方式也在一定程度上基于对原始文本的打分。一般而言，将文本摘要看作是一个分类任务就是要将某一个句子是否属于摘要作为二分类的问题，但是往往没有现成的数据集可以使用，因此，在有的论文中提出了使用文本相似度或者评价指标的方式来为文本设置标签【Neural Document Summarization by Jointly Learning to Score and Select Sentences】。不过在最近也有提出使用生成式模型来得到句子的摘要得分，来提高打标签的效果的方法【Neural Latent Extractive Document Summarization  】

#### 生成式文本摘要

由于s2s的生成式模型在机器翻译领域取得了比较好的成果，所以在不久之后就被应用在生成式文本摘要之中，【A Neural Attention Model for Abstractive Sentence Summarization】使用attention机制对原文进行编码，同时使用简单的语言模型，来生成摘要文本。【Neural machine translation by jointly learning to align and translate.  】是处理机器翻译任务，其中为了保证文本的长效依赖，让每一个rnn的生成步都对前面的所有的步骤进行attention的操作也在后续的研究中被大量借鉴。

后续的方法大部分都是基于这种encoder-decoder的模型的，主要区别体现在特征提取和生成步骤上进行一些优化。作为一个提高生成质量的主要方法，Beam  search被广泛使用在文本生成类的任务之中。对于他的改进方法也有很多，从实验结果上看都可以一定程度上提高生成文本的可读性和效果。





### 二.方法介绍



#### 1.特征处理

对于文书的特征处理模块，特征的组织形式，特征的提取方式，数据集的选择，特征的种类和维度都是需要考虑的，目前来看，较为流行的特征提取方式有

- 使用bert和transformer的预训练加fine tuning模型。【BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding】

这也是当前NLP各个任务提高产出效果的主流方法，通过这种预训练的方式能够很好的帮助下游任务的完成，结合这种方式来提高文本生成的效果也是目前可以采用的方法之一

- 使用主题特征【A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization】

很多相关的论文都提到了类似的方法，使用LDA的语言模型来给出原文中单词的主题信息，再将主题信息补充到单词的embedding向量中

- 使用一些其他的相关信息。组内其他的同学的增加法条相关信息

#### 2.生成模型

文本的生成模块的功能是提高生成文本的阅读效果，同时结合文本本身的信息。包含模型的设计，优化策略两个问题。

模型选择和优化策略的区别在于，前者表示的是模型在训练以及生成中进行的操作，或者是增加可训练的模块，后者则是模型在生成中采用的一些提升的手段。

**+模型选择**

seq2seq是生成模型的最简单的选择，这个设计本身就会包含很多变体，使用LSTM抑或是GRU，或者是使用CNN作为生产模型，都是可以作为对比模型的

- LSTM【】
- GRU【】
- CNNs2s【A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization】

在上述模型的基础之上添加attention机制是常见的思路。【A Neural Attention Model for Abstractive Sentence Summarization】

**+ 修改损失函数**

- 使用互信息作为损失函数的一部分，同时修改互信息的计算方式，使得互信息【Mutual information and diverse decoding improve neural machine translation】

#### 3.优化策略

目前可以提高文本生成质量的策略有很多，对于评论文本生成质量的提高，有一些前置实验，一般而言生成文本的质量主要面临的问题是文本的重复性和文本的平凡语义的问题，这两种问题出现的主要的原因都是s2s模型在使用大数据集进行训练的时候，数据集中的不均衡性导致的，所以一些主流的方法都是借助减少训练文档中的重复单词，或者是为训练文档中的语料按照文本本身的特异性进行打分，借此重新平衡训练集的权重。

主要的解决方案有以下几种。

- BEAMsearch机制（以及其优化策略 ）

【Mutual information and diverse decoding improve neural machine translation】使用改变互信息的计算方法的方式，改变beam search过程中的优化方向

【A Simple, Fast Diverse Decoding Algorithm for Neural Generation-2016] 】使用多元化beam search方法，

- 训练权重的re-weight机制 【Towards Less Generic Responses in Neural Conversation Models: A Statistical Re-weighting Method】

#### 4.强化学习方法

在很多17-18年的论文中都涉及到了强化学习的方法，强化学习的方式在文本摘要当中会出现，在对话系统中也会出现，一般强化学习的模式为生成式对抗或者基于一些常见指标的强化学习。

- 使用基本的强化学习算法SCST【A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization】
- 使用对抗学习的方法【Adversarial learning for neural dialogue generation】
- 同样是提高生成效果的方法【Deep reinforcement learning for dialogue generation】



以上方法大部分式在生成式文本摘要的问题中进行的

#### 5.抽取式摘要方法

很多的论文中出现了抽取式摘要和生成式摘要结合的办法，比如point网络，基于GMM的学习方式等。



【 Jointly Learning Topics in Sentence Embedding for Document Summarization 】中使用了一种基于无监督学习的主题模型方法，对文本的句子编码应用聚类分析，产生每一个句子的主题向量，再根据主题向量来预测某一个句子是否是属于摘要句子的。





### 三.数据集以及模块

BERT





DUC

CNN/Daily Mail【Teaching Machines to Read and Comprehend】





### 四.验证方式



ROUGE

BLEU

